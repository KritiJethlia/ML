{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imorting all libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and shuffle data\n",
    "\n",
    "df = pd.read_csv(\"dataset_comb.csv\")\n",
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
       "       'ConvexArea', 'EquivDiameter', 'Extent', 'Perimeter', 'Roundness',\n",
       "       'AspectRation', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping id column as it is not a valid attribute to train model\n",
    "df = df.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>6705</td>\n",
       "      <td>157.372207</td>\n",
       "      <td>55.063162</td>\n",
       "      <td>0.936790</td>\n",
       "      <td>6870</td>\n",
       "      <td>92.396272</td>\n",
       "      <td>0.667164</td>\n",
       "      <td>353.260</td>\n",
       "      <td>0.675180</td>\n",
       "      <td>2.858031</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>8081</td>\n",
       "      <td>145.843262</td>\n",
       "      <td>71.336831</td>\n",
       "      <td>0.872209</td>\n",
       "      <td>8266</td>\n",
       "      <td>101.434948</td>\n",
       "      <td>0.648191</td>\n",
       "      <td>355.420</td>\n",
       "      <td>0.803880</td>\n",
       "      <td>2.044431</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>6205</td>\n",
       "      <td>161.666140</td>\n",
       "      <td>49.394290</td>\n",
       "      <td>0.952182</td>\n",
       "      <td>6336</td>\n",
       "      <td>88.884483</td>\n",
       "      <td>0.447691</td>\n",
       "      <td>353.795</td>\n",
       "      <td>0.622943</td>\n",
       "      <td>3.272972</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>5448</td>\n",
       "      <td>138.971398</td>\n",
       "      <td>50.930427</td>\n",
       "      <td>0.930425</td>\n",
       "      <td>5637</td>\n",
       "      <td>83.286308</td>\n",
       "      <td>0.534589</td>\n",
       "      <td>318.403</td>\n",
       "      <td>0.675294</td>\n",
       "      <td>2.728652</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>5239</td>\n",
       "      <td>137.924163</td>\n",
       "      <td>49.451511</td>\n",
       "      <td>0.933514</td>\n",
       "      <td>5370</td>\n",
       "      <td>81.673141</td>\n",
       "      <td>0.496117</td>\n",
       "      <td>308.416</td>\n",
       "      <td>0.692125</td>\n",
       "      <td>2.789079</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>5604</td>\n",
       "      <td>146.445155</td>\n",
       "      <td>49.557582</td>\n",
       "      <td>0.941001</td>\n",
       "      <td>5766</td>\n",
       "      <td>84.470317</td>\n",
       "      <td>0.526692</td>\n",
       "      <td>326.458</td>\n",
       "      <td>0.660775</td>\n",
       "      <td>2.955050</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>7332</td>\n",
       "      <td>136.565422</td>\n",
       "      <td>69.425692</td>\n",
       "      <td>0.861139</td>\n",
       "      <td>7490</td>\n",
       "      <td>96.619834</td>\n",
       "      <td>0.692744</td>\n",
       "      <td>340.657</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>1.967073</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>5435</td>\n",
       "      <td>139.801372</td>\n",
       "      <td>50.182232</td>\n",
       "      <td>0.933355</td>\n",
       "      <td>5544</td>\n",
       "      <td>83.186880</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>314.942</td>\n",
       "      <td>0.688570</td>\n",
       "      <td>2.785874</td>\n",
       "      <td>jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12980</th>\n",
       "      <td>8278</td>\n",
       "      <td>151.898208</td>\n",
       "      <td>70.099750</td>\n",
       "      <td>0.887145</td>\n",
       "      <td>8486</td>\n",
       "      <td>102.663903</td>\n",
       "      <td>0.575341</td>\n",
       "      <td>365.958</td>\n",
       "      <td>0.776735</td>\n",
       "      <td>2.166887</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>8858</td>\n",
       "      <td>164.093707</td>\n",
       "      <td>69.650484</td>\n",
       "      <td>0.905449</td>\n",
       "      <td>9017</td>\n",
       "      <td>106.199604</td>\n",
       "      <td>0.556687</td>\n",
       "      <td>384.395</td>\n",
       "      <td>0.753338</td>\n",
       "      <td>2.355959</td>\n",
       "      <td>Gonen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "3858   6705       157.372207        55.063162      0.936790        6870   \n",
       "9577   8081       145.843262        71.336831      0.872209        8266   \n",
       "9689   6205       161.666140        49.394290      0.952182        6336   \n",
       "1974   5448       138.971398        50.930427      0.930425        5637   \n",
       "2777   5239       137.924163        49.451511      0.933514        5370   \n",
       "...     ...              ...              ...           ...         ...   \n",
       "5450   5604       146.445155        49.557582      0.941001        5766   \n",
       "7152   7332       136.565422        69.425692      0.861139        7490   \n",
       "2725   5435       139.801372        50.182232      0.933355        5544   \n",
       "12980  8278       151.898208        70.099750      0.887145        8486   \n",
       "17432  8858       164.093707        69.650484      0.905449        9017   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation    Class  \n",
       "3858       92.396272  0.667164    353.260   0.675180      2.858031  jasmine  \n",
       "9577      101.434948  0.648191    355.420   0.803880      2.044431    Gonen  \n",
       "9689       88.884483  0.447691    353.795   0.622943      3.272972  jasmine  \n",
       "1974       83.286308  0.534589    318.403   0.675294      2.728652  jasmine  \n",
       "2777       81.673141  0.496117    308.416   0.692125      2.789079  jasmine  \n",
       "...              ...       ...        ...        ...           ...      ...  \n",
       "5450       84.470317  0.526692    326.458   0.660775      2.955050  jasmine  \n",
       "7152       96.619834  0.692744    340.657   0.793958      1.967073    Gonen  \n",
       "2725       83.186880  0.497802    314.942   0.688570      2.785874  jasmine  \n",
       "12980     102.663903  0.575341    365.958   0.776735      2.166887    Gonen  \n",
       "17432     106.199604  0.556687    384.395   0.753338      2.355959    Gonen  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max normalisation\n",
    "#convert class variables:   0 - jasmine & 1 - Gonen\n",
    "\n",
    "for column in df.columns:\n",
    "    if column!='Class':\n",
    "        maxx = df[column].max()\n",
    "        minn = df[column].min()\n",
    "        for e in df[column]:\n",
    "            e1 = (maxx - e)/(maxx - minn)\n",
    "            df[column] = df[column].replace(e, e1)\n",
    "    elif column == 'Class':\n",
    "        for e in df[column]:\n",
    "            if e == 'jasmine':\n",
    "                df[column] = df[column].replace(e, 0)\n",
    "            elif e == 'Gonen':\n",
    "                df[column] = df[column].replace(e, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Roundness</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>0.455905</td>\n",
       "      <td>0.236887</td>\n",
       "      <td>0.570983</td>\n",
       "      <td>0.103346</td>\n",
       "      <td>0.490924</td>\n",
       "      <td>1.954014</td>\n",
       "      <td>0.435911</td>\n",
       "      <td>0.498404</td>\n",
       "      <td>0.314409</td>\n",
       "      <td>0.412659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>0.276925</td>\n",
       "      <td>0.342581</td>\n",
       "      <td>0.232940</td>\n",
       "      <td>0.325943</td>\n",
       "      <td>0.325305</td>\n",
       "      <td>1.953487</td>\n",
       "      <td>0.473606</td>\n",
       "      <td>1.627244</td>\n",
       "      <td>0.138146</td>\n",
       "      <td>0.731253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>0.520942</td>\n",
       "      <td>0.197521</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>0.050296</td>\n",
       "      <td>0.554277</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.871950</td>\n",
       "      <td>0.496687</td>\n",
       "      <td>0.385951</td>\n",
       "      <td>0.250174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.619407</td>\n",
       "      <td>0.405580</td>\n",
       "      <td>0.656829</td>\n",
       "      <td>0.125284</td>\n",
       "      <td>0.637205</td>\n",
       "      <td>1.954014</td>\n",
       "      <td>0.699305</td>\n",
       "      <td>0.610306</td>\n",
       "      <td>0.314253</td>\n",
       "      <td>0.463322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>0.646592</td>\n",
       "      <td>0.415181</td>\n",
       "      <td>0.687550</td>\n",
       "      <td>0.114639</td>\n",
       "      <td>0.668881</td>\n",
       "      <td>1.954015</td>\n",
       "      <td>0.775739</td>\n",
       "      <td>0.642368</td>\n",
       "      <td>0.291202</td>\n",
       "      <td>0.439660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>0.599116</td>\n",
       "      <td>0.337063</td>\n",
       "      <td>0.685347</td>\n",
       "      <td>0.088832</td>\n",
       "      <td>0.621901</td>\n",
       "      <td>1.953577</td>\n",
       "      <td>0.714995</td>\n",
       "      <td>1.630604</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.374667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>0.374350</td>\n",
       "      <td>0.427638</td>\n",
       "      <td>0.272639</td>\n",
       "      <td>0.364098</td>\n",
       "      <td>0.417369</td>\n",
       "      <td>1.954023</td>\n",
       "      <td>0.385091</td>\n",
       "      <td>0.538864</td>\n",
       "      <td>0.151734</td>\n",
       "      <td>0.761546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>0.621098</td>\n",
       "      <td>0.397971</td>\n",
       "      <td>0.672371</td>\n",
       "      <td>0.115185</td>\n",
       "      <td>0.648238</td>\n",
       "      <td>1.953584</td>\n",
       "      <td>0.772392</td>\n",
       "      <td>1.630485</td>\n",
       "      <td>0.296070</td>\n",
       "      <td>0.440915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12980</th>\n",
       "      <td>0.251301</td>\n",
       "      <td>0.287071</td>\n",
       "      <td>0.258637</td>\n",
       "      <td>0.274463</td>\n",
       "      <td>0.299205</td>\n",
       "      <td>1.953481</td>\n",
       "      <td>0.618342</td>\n",
       "      <td>0.457640</td>\n",
       "      <td>0.175323</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>0.175858</td>\n",
       "      <td>0.175266</td>\n",
       "      <td>0.267969</td>\n",
       "      <td>0.211373</td>\n",
       "      <td>0.236208</td>\n",
       "      <td>1.953462</td>\n",
       "      <td>0.655402</td>\n",
       "      <td>0.398451</td>\n",
       "      <td>0.207366</td>\n",
       "      <td>0.609263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "3858   0.455905         0.236887         0.570983      0.103346    0.490924   \n",
       "9577   0.276925         0.342581         0.232940      0.325943    0.325305   \n",
       "9689   0.520942         0.197521         0.688739      0.050296    0.554277   \n",
       "1974   0.619407         0.405580         0.656829      0.125284    0.637205   \n",
       "2777   0.646592         0.415181         0.687550      0.114639    0.668881   \n",
       "...         ...              ...              ...           ...         ...   \n",
       "5450   0.599116         0.337063         0.685347      0.088832    0.621901   \n",
       "7152   0.374350         0.427638         0.272639      0.364098    0.417369   \n",
       "2725   0.621098         0.397971         0.672371      0.115185    0.648238   \n",
       "12980  0.251301         0.287071         0.258637      0.274463    0.299205   \n",
       "17432  0.175858         0.175266         0.267969      0.211373    0.236208   \n",
       "\n",
       "       EquivDiameter    Extent  Perimeter  Roundness  AspectRation  Class  \n",
       "3858        1.954014  0.435911   0.498404   0.314409      0.412659      0  \n",
       "9577        1.953487  0.473606   1.627244   0.138146      0.731253      1  \n",
       "9689        1.954015  0.871950   0.496687   0.385951      0.250174      0  \n",
       "1974        1.954014  0.699305   0.610306   0.314253      0.463322      0  \n",
       "2777        1.954015  0.775739   0.642368   0.291202      0.439660      0  \n",
       "...              ...       ...        ...        ...           ...    ...  \n",
       "5450        1.953577  0.714995   1.630604   0.334138      0.374667      0  \n",
       "7152        1.954023  0.385091   0.538864   0.151734      0.761546      1  \n",
       "2725        1.953584  0.772392   1.630485   0.296070      0.440915      0  \n",
       "12980       1.953481  0.618342   0.457640   0.175323      0.683301      1  \n",
       "17432       1.953462  0.655402   0.398451   0.207366      0.609263      1  \n",
       "\n",
       "[18185 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into 7 folds\n",
    "\n",
    "data_g = np.array_split(data, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log_test = []\n",
    "accuracy_log_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn \n",
    "    clf = LogisticRegression(random_state = 0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_log = clf.predict(test_data_xn)\n",
    "    train_pred_y_log = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_log = accuracy_score(test_data_yn, test_pred_y_log)\n",
    "    accuracy_log_test.append(acc1_log)\n",
    "    \n",
    "    acc2_log = accuracy_score(train_data_yn, train_pred_y_log)\n",
    "    accuracy_log_train.append(acc2_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9870221589504187\n",
      "Mean accuracy for train set =  0.987141414896357\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_log_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_log_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lp_test = []\n",
    "accuracy_lp_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "\n",
    "    #convert into array  \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = Perceptron(tol = 1e-3, random_state=0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_lp = clf.predict(test_data_xn)\n",
    "    train_pred_y_lp = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_lp = accuracy_score(test_data_yn, test_pred_y_lp)\n",
    "    accuracy_lp_test.append(acc1_lp)\n",
    "    \n",
    "    acc2_lp = accuracy_score(train_data_yn, train_pred_y_lp)\n",
    "    accuracy_lp_train.append(acc2_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9819630260550277\n",
      "Mean accuracy for train set =  0.981633236352816\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_lp_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_lp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm_test = []\n",
    "accuracy_svm_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = SVC(kernel = 'rbf')\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_svm = clf.predict(test_data_xn)\n",
    "    train_pred_y_svm = clf.predict(train_data_xn)\n",
    "\n",
    "    #calculating and appending accuracies\n",
    "    acc1_svm = accuracy_score(test_data_yn, test_pred_y_svm)\n",
    "    accuracy_svm_test.append(acc1_svm)\n",
    "    \n",
    "    acc2_svm = accuracy_score(train_data_yn, train_pred_y_svm)\n",
    "    accuracy_svm_train.append(acc2_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9882318807144129\n",
      "Mean accuracy for train set =  0.9886811425044787\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_svm_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_svm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_nb_test = []\n",
    "accuracy_nb_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "       \n",
    "    #convert into array         \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_nb = clf.predict(test_data_xn)\n",
    "    train_pred_y_nb = clf.predict(train_data_xn)\n",
    "\n",
    "    #calculating and appending accuracies\n",
    "    acc1_nb = accuracy_score(test_data_yn, test_pred_y_nb)\n",
    "    accuracy_nb_test.append(acc1_nb)\n",
    "    \n",
    "    acc2_nb = accuracy_score(train_data_yn, train_pred_y_nb)\n",
    "    accuracy_nb_train.append(acc2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9846026095553664\n",
      "Mean accuracy for train set =  0.9846576812856449\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_nb_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_nb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Linear Discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_fl_test = []\n",
    "accuracy_fl_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_fl = clf.predict(test_data_xn)\n",
    "    train_pred_y_fl = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_fl = accuracy_score(test_data_yn, test_pred_y_fl)\n",
    "    accuracy_fl_test.append(acc1_fl)\n",
    "    \n",
    "    acc2_fl = accuracy_score(train_data_yn, train_pred_y_fl)\n",
    "    accuracy_fl_train.append(acc2_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.984107723379187\n",
      "Mean accuracy for train set =  0.9840527898296401\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_fl_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_fl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ann_test = []\n",
    "accuracy_ann_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (10, 10, 10, 10,), max_iter = 1000, activation = 'logistic', solver = 'adam', \n",
    "                        random_state = 1)\n",
    "    \n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_ann = clf.predict(test_data_xn)\n",
    "    train_pred_y_ann = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_ann = accuracy_score(test_data_yn, test_pred_y_ann)\n",
    "    accuracy_ann_test.append(acc1_ann)\n",
    "    \n",
    "    acc2_ann = accuracy_score(train_data_yn, train_pred_y_ann)\n",
    "    accuracy_ann_train.append(acc2_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for test set =  0.9879569651232816\n",
      "Mean accuracy for train set =  0.9877371470851989\n"
     ]
    }
   ],
   "source": [
    "#printing accuracies \n",
    "\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_ann_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_ann_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.boxplot([accuracy_log_test, accuracy_lp_test, accuracy_svm_test, accuracy_nb_test, accuracy_fl_test, accuracy_ann_test])\n",
    "\n",
    "plt.text(0.75, 0.98, \"Logistic Regression\")\n",
    "plt.text(0.80, statistics.mean(accuracy_log_test) + 0.0006, \"Mean: \" + str(round(statistics.mean(accuracy_log_test), 5)))\n",
    "\n",
    "plt.text(1.75, 0.99, \"Linear Perceptron\")\n",
    "plt.text(1.82, statistics.mean(accuracy_lp_test) + 0.0001, \"Mean: \" + str(round(statistics.mean(accuracy_lp_test), 5)))\n",
    "\n",
    "plt.text(2.70, 0.98, \"Support Vector Machine\")\n",
    "plt.text(2.82, statistics.mean(accuracy_svm_test) + 0.0002, \"Mean: \" + str(round(statistics.mean(accuracy_svm_test), 5)))\n",
    "\n",
    "plt.text(3.85, 0.98, \"Naive Bayes\")\n",
    "plt.text(3.80, statistics.mean(accuracy_nb_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_nb_test), 5)))\n",
    "\n",
    "plt.text(4.68, 0.98, \"Fisher Linear Discriminant\")\n",
    "plt.text(4.80, statistics.mean(accuracy_fl_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_fl_test), 5)))\n",
    "\n",
    "plt.text(5.68, 0.98, \"Artificial Neural Networks\")\n",
    "plt.text(5.80, statistics.mean(accuracy_ann_test), \"Mean: \" + str(round(statistics.mean(accuracy_ann_test), 5)))\n",
    "\n",
    "#plt.savefig(\"boxPlot.jpeg\")\n",
    "\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
